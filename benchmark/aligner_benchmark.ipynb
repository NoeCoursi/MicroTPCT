{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: pynvml in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (13.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: line_profiler in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.0.0 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from pynvml) (13.590.44)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniforge3\\envs\\env1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install psutil pandas pynvml tqdm line_profiler matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import logging\n",
    "from functools import wraps\n",
    "\n",
    "# Logging configuration: write execution details to a log file\n",
    "logging.basicConfig(\n",
    "    filename=\"benchmark.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "# Optional GPU memory tracking via NVIDIA NVML\n",
    "GPU_AVAILABLE = False\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    GPU_AVAILABLE = True\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-run measurement utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_once(fn, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Run a function once and collect timing, CPU and memory statistics.\n",
    "    Uses tracemalloc for peak Python-level memory and psutil for process memory.\n",
    "    GPU usage recorded if NVML available.\n",
    "    \"\"\"\n",
    "    cpu_before = process.cpu_percent(interval=None)\n",
    "    mem_before = process.memory_info().rss\n",
    "\n",
    "    tracemalloc.start()\n",
    "    t0 = time.perf_counter()\n",
    "    result = fn(*args, **kwargs)\n",
    "    t1 = time.perf_counter()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    cpu_after = process.cpu_percent(interval=0.1)\n",
    "    mem_after = process.memory_info().rss\n",
    "\n",
    "    gpu_used = None\n",
    "    if GPU_AVAILABLE:\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        gpu_used = info.used / 1e6\n",
    "\n",
    "    return {\n",
    "        \"time_seconds\": t1 - t0,\n",
    "        \"cpu_percent_avg\": (cpu_before + cpu_after) / 2,\n",
    "        \"memory_used_MB\": (mem_after - mem_before) / 1e6,\n",
    "        \"peak_memory_traced_MB\": peak / 1e6,\n",
    "        \"gpu_memory_used_MB\": gpu_used,\n",
    "        \"result\": result,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-run benchmark decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(runs=5):\n",
    "    \"\"\"\n",
    "    Decorator that executes a function multiple times and aggregates statistics.\n",
    "    Returns mean and standard deviation for timing and resource usage.\n",
    "    \"\"\"\n",
    "    def decorator(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            records = []\n",
    "            for _ in range(runs):\n",
    "                rec = run_once(fn, *args, **kwargs)\n",
    "                records.append(rec)\n",
    "\n",
    "            return {\n",
    "                \"function\": fn.__name__,\n",
    "                \"time_mean\": statistics.mean(r[\"time_seconds\"] for r in records),\n",
    "                \"time_std\": statistics.stdev(r[\"time_seconds\"] for r in records) if runs > 1 else 0,\n",
    "                \"cpu_mean\": statistics.mean(r[\"cpu_percent_avg\"] for r in records),\n",
    "                \"mem_mean_MB\": statistics.mean(r[\"memory_used_MB\"] for r in records),\n",
    "                \"peak_mem_mean_MB\": statistics.mean(r[\"peak_memory_traced_MB\"] for r in records),\n",
    "                \"gpu_mem_mean_MB\": (\n",
    "                    statistics.mean(r[\"gpu_memory_used_MB\"] for r in records)\n",
    "                    if GPU_AVAILABLE else None\n",
    "                ),\n",
    "            }\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example algorithms + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark(runs=5)\n",
    "def sort_list(n=500_000):\n",
    "    \"\"\"Reverse and sort a large list.\"\"\"\n",
    "    data = list(range(n))\n",
    "    data.reverse()\n",
    "    return sorted(data)\n",
    "\n",
    "@benchmark(runs=5)\n",
    "def fibonacci_iter(n=35):\n",
    "    \"\"\"Compute Fibonacci using an iterative loop (fast).\"\"\"\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a+b\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS = [\n",
    "    (sort_list, {\"n\": 200_000}),\n",
    "    (sort_list, {\"n\": 1_000_000}),\n",
    "    (fibonacci_iter, {\"n\": 35}),\n",
    "    (fibonacci_iter, {\"n\": 45}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential execution + progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential benchmarks: 100%|██████████| 4/4 [00:07<00:00,  1.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>function</th>\n",
       "      <th>time_mean</th>\n",
       "      <th>time_std</th>\n",
       "      <th>cpu_mean</th>\n",
       "      <th>mem_mean_MB</th>\n",
       "      <th>peak_mem_mean_MB</th>\n",
       "      <th>gpu_mem_mean_MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n': 200000}</td>\n",
       "      <td>sort_list</td>\n",
       "      <td>0.194722</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.078950</td>\n",
       "      <td>9.621717</td>\n",
       "      <td>156.831744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'n': 1000000}</td>\n",
       "      <td>sort_list</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>0.138639</td>\n",
       "      <td>10.08</td>\n",
       "      <td>39.800832</td>\n",
       "      <td>48.021569</td>\n",
       "      <td>156.831744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n': 35}</td>\n",
       "      <td>fibonacci_iter</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>12.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>156.831744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'n': 45}</td>\n",
       "      <td>fibonacci_iter</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>156.831744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           params        function  time_mean  time_std  cpu_mean  mem_mean_MB  \\\n",
       "0   {'n': 200000}       sort_list   0.194722  0.053285      0.00     8.078950   \n",
       "1  {'n': 1000000}       sort_list   0.853834  0.138639     10.08    39.800832   \n",
       "2       {'n': 35}  fibonacci_iter   0.000049  0.000012     12.02     0.000000   \n",
       "3       {'n': 45}  fibonacci_iter   0.000075  0.000024      0.00     0.000000   \n",
       "\n",
       "   peak_mem_mean_MB  gpu_mem_mean_MB  \n",
       "0          9.621717       156.831744  \n",
       "1         48.021569       156.831744  \n",
       "2          0.000158       156.831744  \n",
       "3          0.000159       156.831744  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for fn, params in tqdm(TESTS, desc=\"Sequential benchmarks\"):\n",
    "    res = fn(**params)\n",
    "    logging.info(f\"[SEQ] Bench {fn.__name__} params={params}: {res}\")\n",
    "    results.append({\"params\": params, **res})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel execution (CPU multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def run_single(param_tuple):\n",
    "    \"\"\"\n",
    "    Wrapper to allow multiprocessing execution.\n",
    "    \"\"\"\n",
    "    fn, params = param_tuple\n",
    "    res = fn(**params)\n",
    "    logging.info(f\"[PARALLEL] Bench {fn.__name__} params={params}: {res}\")\n",
    "    return {\"params\": params, **res}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(cpu_count()) as p:\n",
    "        df_parallel = pd.DataFrame(p.map(run_single, TESTS))\n",
    "df_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the line profiler extension once at notebook start\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Example profiling call (change function as needed)\n",
    "%lprun -f sort_list sort_list(n=300_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(df, metric):\n",
    "    \"\"\"\n",
    "    Produce simple exploratory visualizations for benchmarking metrics.\n",
    "    Boxplot and violin plot are produced on separate figures.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    df.boxplot(column=[metric])\n",
    "    plt.title(f\"Boxplot of {metric}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    df[metric].plot(kind='violin')\n",
    "    plt.title(f\"Violin plot of {metric}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate plots for core metrics\n",
    "for m in [\"time_mean\", \"cpu_mean\", \"mem_mean_MB\"]:\n",
    "    plot_metric(df, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"benchmark_full_results.csv\", index=False)\n",
    "df_parallel.to_csv(\"benchmark_parallel_results.csv\", index=False)\n",
    "print(\"All benchmarking complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env1)",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
